{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALeRCE classes\n",
    "\n",
    "https://github.com/ZwickyTransientFacility/ztf-avro-alert\n",
    "\n",
    "1. **AGN:** Active Galactic Nuclei\n",
    "1. **Blazar:** Blazar\n",
    "1. **CV/Nova:** Cataclysmic Variable Star/Nova\n",
    "1. **Ceph:** Cepheid Variable Star\n",
    "1. **DSCT:** Delta Scuti Star\n",
    "1. **EA:** Eclipsing Algol\n",
    "1. **EB/EW:** Eclipsing Binaries/Eclipsing W Ursa Majoris\n",
    "1. **LPV:** Long Period Variable\n",
    "1. **Periodic-Other:** Periodic-Other\n",
    "1. **QSO:** Quasi-Stellar Object\n",
    "1. **RRL:** RRLyrae Variable Star\n",
    "1. **RSCVn:** RS Canum Venaticorum\n",
    "1. **SLSN:** Super Luminous Supernova\n",
    "1. **SNII:** Supernova II\n",
    "1. **SNIIb:** Supernova IIb\n",
    "1. **SNIIn:** Supernova IIn\n",
    "1. **SNIa:** Supernova Ia\n",
    "1. **SNIbc:** Supernova Ibc\n",
    "1. **TDE:** Tidal disruption event (to remove)\n",
    "1. **YSO:** Young Stellar Object\n",
    "1. **ZZ:** ZZ Ceti Stars (to remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns names\n",
    "1. **oid:** object id\n",
    "1. **classALeRCE:** object class name\n",
    "1. **fid:** band index, g=1, r=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_df; columns=['classALeRCE', 'ra', 'dec', 'period', 'source', 'id_source', 'class_source', 'separation_arcsec']; id=oid\n",
      "features_train_df; id=oid\n",
      "(0) - Amplitude_1\n",
      "(1) - Amplitude_2\n",
      "(2) - AndersonDarling_1\n",
      "(3) - AndersonDarling_2\n",
      "(4) - Autocor_length_1\n",
      "(5) - Autocor_length_2\n",
      "(6) - Beyond1Std_1\n",
      "(7) - Beyond1Std_2\n",
      "(8) - Con_1\n",
      "(9) - Con_2\n",
      "(10) - Eta_e_1\n",
      "(11) - Eta_e_2\n",
      "(12) - ExcessVar_1\n",
      "(13) - ExcessVar_2\n",
      "(14) - GP_DRW_sigma_1\n",
      "(15) - GP_DRW_sigma_2\n",
      "(16) - GP_DRW_tau_1\n",
      "(17) - GP_DRW_tau_2\n",
      "(18) - Gskew_1\n",
      "(19) - Gskew_2\n",
      "(20) - Harmonics_mag_1_1\n",
      "(21) - Harmonics_mag_1_2\n",
      "(22) - Harmonics_mag_2_1\n",
      "(23) - Harmonics_mag_2_2\n",
      "(24) - Harmonics_mag_3_1\n",
      "(25) - Harmonics_mag_3_2\n",
      "(26) - Harmonics_mag_4_1\n",
      "(27) - Harmonics_mag_4_2\n",
      "(28) - Harmonics_mag_5_1\n",
      "(29) - Harmonics_mag_5_2\n",
      "(30) - Harmonics_mag_6_1\n",
      "(31) - Harmonics_mag_6_2\n",
      "(32) - Harmonics_mag_7_1\n",
      "(33) - Harmonics_mag_7_2\n",
      "(34) - Harmonics_mse_1\n",
      "(35) - Harmonics_mse_2\n",
      "(36) - Harmonics_phase_2_1\n",
      "(37) - Harmonics_phase_2_2\n",
      "(38) - Harmonics_phase_3_1\n",
      "(39) - Harmonics_phase_3_2\n",
      "(40) - Harmonics_phase_4_1\n",
      "(41) - Harmonics_phase_4_2\n",
      "(42) - Harmonics_phase_5_1\n",
      "(43) - Harmonics_phase_5_2\n",
      "(44) - Harmonics_phase_6_1\n",
      "(45) - Harmonics_phase_6_2\n",
      "(46) - Harmonics_phase_7_1\n",
      "(47) - Harmonics_phase_7_2\n",
      "(48) - IAR_phi_1\n",
      "(49) - IAR_phi_2\n",
      "(50) - LinearTrend_1\n",
      "(51) - LinearTrend_2\n",
      "(52) - MHPS_PN_flag_1\n",
      "(53) - MHPS_PN_flag_2\n",
      "(54) - MHPS_high_1\n",
      "(55) - MHPS_high_2\n",
      "(56) - MHPS_low_1\n",
      "(57) - MHPS_low_2\n",
      "(58) - MHPS_non_zero_1\n",
      "(59) - MHPS_non_zero_2\n",
      "(60) - MHPS_ratio_1\n",
      "(61) - MHPS_ratio_2\n",
      "(62) - MaxSlope_1\n",
      "(63) - MaxSlope_2\n",
      "(64) - Mean_1\n",
      "(65) - Mean_2\n",
      "(66) - Meanvariance_1\n",
      "(67) - Meanvariance_2\n",
      "(68) - MedianAbsDev_1\n",
      "(69) - MedianAbsDev_2\n",
      "(70) - MedianBRP_1\n",
      "(71) - MedianBRP_2\n",
      "(72) - Multiband_period\n",
      "(73) - PairSlopeTrend_1\n",
      "(74) - PairSlopeTrend_2\n",
      "(75) - PercentAmplitude_1\n",
      "(76) - PercentAmplitude_2\n",
      "(77) - Period_band_1\n",
      "(78) - Period_band_2\n",
      "(79) - Period_fit\n",
      "(80) - Power_rate_1/2\n",
      "(81) - Power_rate_1/3\n",
      "(82) - Power_rate_1/4\n",
      "(83) - Power_rate_2\n",
      "(84) - Power_rate_3\n",
      "(85) - Power_rate_4\n",
      "(86) - Psi_CS_1\n",
      "(87) - Psi_CS_2\n",
      "(88) - Psi_eta_1\n",
      "(89) - Psi_eta_2\n",
      "(90) - Pvar_1\n",
      "(91) - Pvar_2\n",
      "(92) - Q31_1\n",
      "(93) - Q31_2\n",
      "(94) - Rcs_1\n",
      "(95) - Rcs_2\n",
      "(96) - SF_ML_amplitude_1\n",
      "(97) - SF_ML_amplitude_2\n",
      "(98) - SF_ML_gamma_1\n",
      "(99) - SF_ML_gamma_2\n",
      "(100) - SPM_A_1\n",
      "(101) - SPM_A_2\n",
      "(102) - SPM_beta_1\n",
      "(103) - SPM_beta_2\n",
      "(104) - SPM_chi_1\n",
      "(105) - SPM_chi_2\n",
      "(106) - SPM_gamma_1\n",
      "(107) - SPM_gamma_2\n",
      "(108) - SPM_t0_1\n",
      "(109) - SPM_t0_2\n",
      "(110) - SPM_tau_fall_1\n",
      "(111) - SPM_tau_fall_2\n",
      "(112) - SPM_tau_rise_1\n",
      "(113) - SPM_tau_rise_2\n",
      "(114) - Skew_1\n",
      "(115) - Skew_2\n",
      "(116) - SmallKurtosis_1\n",
      "(117) - SmallKurtosis_2\n",
      "(118) - Std_1\n",
      "(119) - Std_2\n",
      "(120) - StetsonK_1\n",
      "(121) - StetsonK_2\n",
      "(122) - delta_mag_fid_1\n",
      "(123) - delta_mag_fid_2\n",
      "(124) - delta_mjd_fid_1\n",
      "(125) - delta_mjd_fid_2\n",
      "(126) - delta_period_1\n",
      "(127) - delta_period_2\n",
      "(128) - dmag_first_det_fid_1\n",
      "(129) - dmag_first_det_fid_2\n",
      "(130) - dmag_non_det_fid_1\n",
      "(131) - dmag_non_det_fid_2\n",
      "(132) - first_mag_1\n",
      "(133) - first_mag_2\n",
      "(134) - g-r_max\n",
      "(135) - g-r_max_corr\n",
      "(136) - g-r_mean\n",
      "(137) - g-r_mean_corr\n",
      "(138) - gal_b\n",
      "(139) - gal_l\n",
      "(140) - iqr_1\n",
      "(141) - iqr_2\n",
      "(142) - last_diffmaglim_before_fid_1\n",
      "(143) - last_diffmaglim_before_fid_2\n",
      "(144) - last_mjd_before_fid_1\n",
      "(145) - last_mjd_before_fid_2\n",
      "(146) - max_diffmaglim_after_fid_1\n",
      "(147) - max_diffmaglim_after_fid_2\n",
      "(148) - max_diffmaglim_before_fid_1\n",
      "(149) - max_diffmaglim_before_fid_2\n",
      "(150) - mean_mag_1\n",
      "(151) - mean_mag_2\n",
      "(152) - median_diffmaglim_after_fid_1\n",
      "(153) - median_diffmaglim_after_fid_2\n",
      "(154) - median_diffmaglim_before_fid_1\n",
      "(155) - median_diffmaglim_before_fid_2\n",
      "(156) - min_mag_1\n",
      "(157) - min_mag_2\n",
      "(158) - n_det_1\n",
      "(159) - n_det_2\n",
      "(160) - n_neg_1\n",
      "(161) - n_neg_2\n",
      "(162) - n_non_det_after_fid_1\n",
      "(163) - n_non_det_after_fid_2\n",
      "(164) - n_non_det_before_fid_1\n",
      "(165) - n_non_det_before_fid_2\n",
      "(166) - n_pos_1\n",
      "(167) - n_pos_2\n",
      "(168) - positive_fraction_1\n",
      "(169) - positive_fraction_2\n",
      "(170) - rb\n",
      "(171) - sgscore1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#survey_name = 'alerceZTFv5.1'\n",
    "survey_name = 'alerceZTFv7.1' # use this dataset\n",
    "df_index_names = {\n",
    "    'oid':'oid', # object id\n",
    "    'label':'classALeRCE', # object class name\n",
    "    'ra':'ra',\n",
    "    'dec':'dec',\n",
    "    'band':'fid', # band\n",
    "    'obs_day':'mjd', # days\n",
    "    'obs':'magpsf_corr', # observations\n",
    "    'obs_error':'sigmapsf_corr', # observation errors\n",
    "}\n",
    "\n",
    "### load files\n",
    "load_root_dir = f'../data/{survey_name}'\n",
    "labels_df = pd.read_parquet(f'{load_root_dir}/labels.parquet')\n",
    "print(f'labels_df; columns={list(labels_df.columns)}; id={labels_df.index.name}')\n",
    "\n",
    "features_train_df = pd.read_parquet(f'{load_root_dir}/features_train.parquet')\n",
    "print(f'features_train_df; id={features_train_df.index.name}')\n",
    "for k,c in enumerate(list(features_train_df.columns)):\n",
    "    print(f'({k}) - {c}')\n",
    "\n",
    "features_test_df = pd.read_parquet(f'{load_root_dir}/features_test.parquet')\n",
    "#print(f'features_test_df - columns: {list(features_test_df.columns)} - id: {features_test_df.index.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mismatch.level_bars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14638/4194336497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmismatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_bars\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLevelBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_index_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mismatch.level_bars'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.level_bars import LevelBar\n",
    "\n",
    "classes, counts = np.unique(labels_df[df_index_names['label']].values, return_counts=True)\n",
    "population_cdict = {c:counts[kc] for kc,c in enumerate(classes)}\n",
    "print(LevelBar(population_cdict, ncols=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_df.info())\n",
    "labels_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train_df.info())\n",
    "features_train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_test_df.info())\n",
    "features_test_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mismatch import _C\n",
    "from mismatch.utils import get_object_features\n",
    "from dask import dataframe as dd\n",
    "\n",
    "### example using dask\n",
    "features_train_ddf = dd.from_pandas(features_train_df, npartitions=_C.N_DASK) # dask dataframe can be faster\n",
    "features_test_ddf = dd.from_pandas(features_test_df, npartitions=_C.N_DASK) # dask dataframe can be faster\n",
    "labels_ddf = dd.from_pandas(labels_df, npartitions=_C.N_DASK) # dask dataframe can be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get all features from an object\n",
    "obj_name = 'ZTF18abvpirg' # from train\n",
    "features, c, features_names = get_object_features(features_train_ddf, labels_ddf, obj_name)\n",
    "fdict = {f:features[kf] for kf,f in enumerate(features_names)}\n",
    "print(f'obj={obj_name}; class={c}; features={len(features)}')\n",
    "for k,key in enumerate(fdict.keys()):\n",
    "    print(f'({k}); {key}={fdict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get features per band from an object\n",
    "obj_name = 'ZTF18abvpirg' # from train\n",
    "band = 1\n",
    "features, c, features_names = get_object_features(features_train_ddf, labels_ddf, obj_name, band=band)\n",
    "fdict = {f:features[kf] for kf,f in enumerate(features_names)}\n",
    "print(f'obj={obj_name}; class={c}; features={len(features)}')\n",
    "for k,key in enumerate(fdict.keys()):\n",
    "    print(f'({k}) {key}={fdict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mismatch import _C\n",
    "from mismatch.utils import get_object_features\n",
    "from dask import dataframe as dd\n",
    "\n",
    "### get features non-band-wise features\n",
    "obj_name = 'ZTF18abvpirg' # from train\n",
    "band = -1\n",
    "features, c, features_names = get_object_features(features_train_ddf, labels_ddf, obj_name, band=band)\n",
    "fdict = {f:features[kf] for kf,f in enumerate(features_names)}\n",
    "print(f'obj={obj_name}; class={c}; features={len(features)}')\n",
    "for k,key in enumerate(fdict.keys()):\n",
    "    print(f'({k}); {key}={fdict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### get features from a non-labeled sample. returned class is None\n",
    "obj_name = 'ZTF17aaacvqh' # from test\n",
    "features, c, features_names = get_object_features(features_test_ddf, labels_ddf, obj_name, band=1)\n",
    "fdict = {f:features[kf] for kf,f in enumerate(features_names)}\n",
    "print(f'obj={obj_name}; class={c}; features={len(features)}')\n",
    "for k,key in enumerate(fdict.keys()):\n",
    "    print(f'({k}); {key}={fdict[key]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
